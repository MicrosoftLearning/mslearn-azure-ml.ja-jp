{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# パイプライン ジョブとしてスクリプトを実行する\n",
        "\n",
        "パイプラインを使用すると、複数のステップを 1 つのワークフローにグループ化することができます。 コンポーネントを使用してパイプラインを構築できます。 各コンポーネントには、実行する Python スクリプトが反映されます。 コンポーネントは、スクリプトとその実行方法を指定する YAML ファイルで定義されます。 \n",
        "\n",
        "## 開始する前に\n",
        "\n",
        "このノートブックでコードを実行するには、最新バージョンの **azureml-ai-ml** パッケージが必要です。 次のセルを実行して、パッケージがインストールされていることを確認します。\n",
        "\n",
        "> **注**:\n",
        "> **azure-ai-ml** パッケージがインストールされていない場合は、`pip install azure-ai-ml` を実行してインストールします。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [],
      "source": [
        "## ワークスペースに接続する\n",
        "\n",
        "必要な SDK パッケージがインストールされているため、ワークスペースに接続できます。\n",
        "\n",
        "ワークスペースに接続するには、識別子パラメーター (サブスクリプション ID、リソース グループ名、ワークスペース名) が必要です。 リソース グループ名とワークスペース名は、既に入力されています。 コマンドを完了するには、サブスクリプション ID のみが必要です。\n",
        "\n",
        "必要なパラメーターを見つけるには、スタジオの右上にあるサブスクリプションとワークスペース名をクリックします。 右側にペインが開きます。\n",
        "\n",
        "<p style=\"color:red;font-size:120%;background-color:yellow;font-weight:bold\"> サブスクリプション ID をコピーし、**YOUR-SUBSCRIPTION-ID** をコピーした値に置き換えます。 </p>"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## スクリプトを作成する\n",
        "\n",
        "次の 2 つの手順でパイプラインを構築します。\n",
        "\n",
        "1. **データを準備する**: 不足しているデータを修正し、データを正規化します。\n",
        "1. **モデルのトレーニング**: デシジョン ツリー分類モデルをトレーニングします。\n",
        "\n",
        "次のセルを実行して、**src** フォルダーと 2 つのスクリプトを作成します。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1663753569264
        },
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [],
      "source": [
        "## コンポーネントを定義する\n",
        "\n",
        "コンポーネントを定義するには、次のように指定する必要があります。\n",
        "\n",
        "- **メタデータ**: \"名前\"、\"表示名\"、\"バージョン\"、\"説明\"、\"種類\" など。メタデータは、コンポーネントの記述と管理に役立ちます。** ** ** ** **\n",
        "- **インターフェイス**: \"入力\" と \"出力\"。** ** たとえば、モデル トレーニング コンポーネントは、トレーニング データと正則化率を入力として受け取り、トレーニング済みのモデル ファイルを出力として生成します。 \n",
        "- **コマンド、コード、環境**: コンポーネントを実行するための \"コマンド\"、\"コード\"、\"環境\"。** ** ** コマンドは、コンポーネントを実行するためのシェル コマンドです。 コードは通常、ソース コード ディレクトリを参照します。 環境は、AzureML 環境 (キュレーションされた環境またはカスタム作成された環境)、Docker イメージ、または conda 環境の場合があります。\n",
        "\n",
        "次のセルを実行して、パイプライン ステップとして実行するコンポーネントごとに YAML を作成します。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [],
      "source": [
        "## コンポーネントを読み込む\n",
        "\n",
        "各コンポーネントを定義したら、YAML ファイルを参照してコンポーネントを読み込むことができます。 "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## パイプラインを構築する\n",
        "\n",
        "コンポーネントを作成して読み込むと、パイプラインを構築できます。 2 つのコンポーネントをパイプラインに作成します。 まず、`prep_data` コンポーネントを実行します。 最初のコンポーネントの出力は、モデルをトレーニングする 2 番目のコンポーネント `train_decision_tree` の入力である必要があります。\n",
        "\n",
        "`diabetes_classification` 関数は、完全なパイプラインを表します。 この関数には 1 つの入力パラメーター `pipeline_job_input` が必要です。 セットアップ中にデータ資産が作成されました。 登録済みのデータ資産をパイプライン入力として使用します。 "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [],
      "source": [
        "`pipeline_job` オブジェクトを印刷すると、パイプライン ジョブの構成を取得できます。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [],
      "source": [
        "パラメーターを参照し、新しい値を指定すると、パイプライン ジョブ構成の任意のパラメーターを変更できます。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [],
      "source": [
        "## パイプライン ジョブを送信する\n",
        "\n",
        "最後に、パイプラインを構築し、必要に応じて実行するようにパイプライン ジョブを構成したら、パイプライン ジョブを送信できます。"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Define the components\n",
        "\n",
        "To define the component you need to specify:\n",
        "\n",
        "- **Metadata**: *name*, *display name*, *version*, *description*, *type* etc. The metadata helps to describe and manage the component.\n",
        "- **Interface**: *inputs* and *outputs*. For example, a model training component will take training data and the regularization rate as input, and generate a trained model file as output. \n",
        "- **Command, code & environment**: the *command*, *code* and *environment* to run the component. Command is the shell command to execute the component. Code usually refers to a source code directory. Environment could be an AzureML environment (curated or custom created), docker image or conda environment.\n",
        "\n",
        "Run the following cells to create a YAML for each component you want to run as a pipeline step."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [],
      "source": [
        "%%writefile prep-data.yml\n",
        "$schema: https://azuremlschemas.azureedge.net/latest/commandComponent.schema.json\n",
        "name: prep_data\n",
        "display_name: Prepare training data\n",
        "version: 1\n",
        "type: command\n",
        "inputs:\n",
        "  input_data: \n",
        "    type: uri_file\n",
        "outputs:\n",
        "  output_data:\n",
        "    type: uri_file\n",
        "code: ./src\n",
        "environment: azureml:AzureML-sklearn-0.24-ubuntu18.04-py37-cpu@latest\n",
        "command: >-\n",
        "  python prep-data.py \n",
        "  --input_data ${{inputs.input_data}}\n",
        "  --output_data ${{outputs.output_data}}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [],
      "source": [
        "%%writefile train-model.yml\n",
        "$schema: https://azuremlschemas.azureedge.net/latest/commandComponent.schema.json\n",
        "name: train_model\n",
        "display_name: Train a decision tree classifier model\n",
        "version: 1\n",
        "type: command\n",
        "inputs:\n",
        "  training_data: \n",
        "    type: uri_file\n",
        "  reg_rate:\n",
        "    type: number\n",
        "    default: 0.01\n",
        "outputs:\n",
        "  model_output:\n",
        "    type: mlflow_model\n",
        "code: ./src\n",
        "environment: azureml:AzureML-sklearn-0.24-ubuntu18.04-py37-cpu@latest\n",
        "command: >-\n",
        "  python train-model.py \n",
        "  --training_data ${{inputs.training_data}} \n",
        "  --reg_rate ${{inputs.reg_rate}} \n",
        "  --model_output ${{outputs.model_output}} "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Load the components\n",
        "\n",
        "Now that you have defined each component, you can load the components by referring to the YAML files. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [],
      "source": [
        "from azure.ai.ml import load_component\n",
        "parent_dir = \"\"\n",
        "\n",
        "prep_data = load_component(source=parent_dir + \"./prep-data.yml\")\n",
        "train_decision_tree = load_component(source=parent_dir + \"./train-model.yml\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Build the pipeline\n",
        "\n",
        "After creating and loading the components, you can build the pipeline. You'll compose the two components into a pipeline. First, you'll want the `prep_data` component to run. The output of the first component should be the input of the second component `train_decision_tree`, which will train the model.\n",
        "\n",
        "The `diabetes_classification` function represents the complete pipeline. The function expects one input variable: `pipeline_job_input`. A data asset was created during setup. You'll use the registered data asset as the pipeline input. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [],
      "source": [
        "from azure.ai.ml import Input\n",
        "from azure.ai.ml.constants import AssetTypes\n",
        "from azure.ai.ml.dsl import pipeline\n",
        "\n",
        "@pipeline()\n",
        "def diabetes_classification(pipeline_job_input):\n",
        "    clean_data = prep_data(input_data=pipeline_job_input)\n",
        "    train_model = train_decision_tree(training_data=clean_data.outputs.output_data)\n",
        "\n",
        "    return {\n",
        "        \"pipeline_job_transformed_data\": clean_data.outputs.output_data,\n",
        "        \"pipeline_job_trained_model\": train_model.outputs.model_output,\n",
        "    }\n",
        "\n",
        "pipeline_job = diabetes_classification(Input(type=AssetTypes.URI_FILE, path=\"azureml:diabetes-data:1\"))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "You can retrieve the configuration of the pipeline job by printing the `pipeline_job` object:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [],
      "source": [
        "print(pipeline_job)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "You can change any parameter of the pipeline job configuration by referring to the parameter and specifying the new value:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [],
      "source": [
        "# change the output mode\n",
        "pipeline_job.outputs.pipeline_job_transformed_data.mode = \"upload\"\n",
        "pipeline_job.outputs.pipeline_job_trained_model.mode = \"upload\"\n",
        "# set pipeline level compute\n",
        "pipeline_job.settings.default_compute = \"aml-cluster\"\n",
        "# set pipeline level datastore\n",
        "pipeline_job.settings.default_datastore = \"workspaceblobstore\"\n",
        "\n",
        "# print the pipeline job again to review the changes\n",
        "print(pipeline_job)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Submit the pipeline job\n",
        "\n",
        "Finally, when you've built the pipeline and configured the pipeline job to run as required, you can submit the pipeline job:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [],
      "source": [
        "# submit job to workspace\n",
        "pipeline_job = ml_client.jobs.create_or_update(\n",
        "    pipeline_job, experiment_name=\"pipeline_diabetes\"\n",
        ")\n",
        "pipeline_job"
      ]
    }
  ],
  "metadata": {
    "kernel_info": {
      "name": "python38-azureml"
    },
    "kernelspec": {
      "display_name": "Python 3.8 - AzureML",
      "language": "python",
      "name": "python38-azureml"
    },
    "microsoft": {
      "host": {
        "AzureML": {
          "notebookHasBeenCompleted": true
        }
      }
    },
    "nteract": {
      "version": "nteract-front-end@1.0.0"
    },
    "vscode": {
      "interpreter": {
        "hash": "f2b2cd046deda8eabef1e765a11d0ec9aa9bd1d31d56ce79c815a38c323e14ec"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}