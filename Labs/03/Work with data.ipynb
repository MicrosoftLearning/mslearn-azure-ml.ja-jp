{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "source": [
        "# データを処理する\n",
        "\n",
        "データは、機械学習モデルが構築される基盤です。 クラウドで一元的にデータを管理し、複数のワークステーションとコンピューティング ターゲットで実験を実行してモデルをトレーニングしているデータ サイエンティストのチームがアクセスできるようにすることは、プロフェッショナルなデータ サイエンス ソリューションでは重要です。\n",
        "\n",
        "このノートブックでは、データを操作するための 2 つの Azure Machine Learning オブジェクト、*データストア*と*データ資産*について学びます。\n",
        "\n",
        "## 開始する前に\n",
        "\n",
        "このノートブックでコードを実行するには、**azureml-ai-ml** パッケージの最新バージョンが必要です。 次のセルを実行して、パッケージがインストールされていることを確認します。\n",
        "\n",
        "> **注**:\n",
        "> **azure-ai-ml** パッケージがインストールされていない場合は、`pip install azure-ai-ml` を実行してインストールします。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1666789326586
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [],
      "source": [
        "## ワークスペースに接続する\n",
        "\n",
        "必要な SDK パッケージがインストールされているため、ワークスペースに接続できます。\n",
        "\n",
        "ワークスペースに接続するには、識別子パラメーター (サブスクリプション ID、リソース グループ名、ワークスペース名) が必要です。 リソース グループ名とワークスペース名は既に入力されています。 コマンドを完了するには、サブスクリプション ID のみが必要です。\n",
        "\n",
        "必要なパラメーターを見つけるには、スタジオの右上にあるサブスクリプションとワークスペース名をクリックします。 右側にペインが開きます。\n",
        "\n",
        "<p style=\"color:red;font-size:120%;background-color:yellow;font-weight:bold\"> サブスクリプション ID をコピーし、**YOUR-SUBSCRIPTION-ID** をコピーした値に置き換えます。 </p>"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "source": [
        "## データストアを一覧表示する\n",
        "\n",
        "Azure Machine Learning ワークスペースを作成すると、Azure ストレージ アカウントも作成されます。 ストレージ アカウントには BLOB ストレージとファイル ストレージが含まれており、**データストア**としてワークスペースに自動的に接続されます。 ワークスペースに接続されているすべてのデータストアを一覧表示できます。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1666789343369
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [],
      "source": [
        "先ほど調べた **azureml-blobstore-...** コンテナーに接続する `workspaceblobstore` に注意してください。 `workspacefilestore` は **code-...** ファイル共有に接続します。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [],
      "source": [
        "## データストアを作成する\n",
        "\n",
        "別の Azure ストレージ サービスを Azure Machine Learning ワークスペースに接続する場合は常に、データストアを作成できます。 データストアを作成すると、ワークスペースとストレージの間の接続が作成され、ストレージ サービス自体は作成されません。 \n",
        "\n",
        "データストアを作成し、(既に存在する) ストレージに接続するには、次のものを指定する必要があります。\n",
        "\n",
        "- 接続するストレージ サービスの種類を示すクラス。 次の例では、BLOB ストレージ (`AzureBlobDatastore`) に接続します。\n",
        "- `name`: Azure Machine Learning ワークスペース内のデータストアの表示名。\n",
        "- `description`: データストアに関する詳細情報を提供する説明 (省略可能)。\n",
        "- `account_name`: Azure ストレージ アカウントの名前。\n",
        "- `container_name`: Azure ストレージ アカウントに BLOB を格納するコンテナーの名前。\n",
        "- `credentials`: 認証方法と認証する資格情報を指定します。 次の例では、アカウント キーを使います。\n",
        "\n",
        "**重要**: \n",
        "- **YOUR-STORAGE-ACCOUNT-NAME** は、自動的に作成されたストレージ アカウントの名前に置き換えます。 \n",
        "- `account_key` の **XXXX-XXXX** は、Azure ストレージ アカウントのアカウント キーに置き換えます。 \n",
        "\n",
        "アカウント キーは、[Azure portal](https://portal.azure.com) に移動し、使用するストレージ アカウントに移動して、 **[アクセス キー]** タブから key1 または key2 の **[キー]** の値をコピーすることによって取得できることに注意してください。 "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "source": [
        "データストアをもう一度一覧表示して、`blob_training_data` という名前の新しいデータストアが作成されたことを確認します。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1666790805418
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [],
      "source": [
        "## データ資産を作成する\n",
        "\n",
        "データストア内の特定のフォルダーまたはファイルをポイントするには、データ資産を作成します。 データ資産には次の 3 種類があります。\n",
        "\n",
        "- `URI_FILE`: 特定のファイルを指します。\n",
        "- `URI_FOLDER`: 特定のフォルダーを指します。\n",
        "- `MLTABLE` は、フォルダー内の 1 つ以上のファイルを読み取る方法を指定する MLTable ファイルを指します。\n",
        "\n",
        "3 種類のデータ資産すべてを作成して、それらの違いを体験しましょう。"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "`URI_FILE` データ資産を作成するには、特定のファイルを指すパスを指定する必要があります。 パスは、ローカル パスまたはクラウド パスにすることができます。\n",
        "\n",
        "次の例では、\"ローカル\" パスを参照してデータ資産を作成します。** Azure Machine Learning ワークスペースを使用するときにデータを常に使用できるようにするために、ローカル ファイルは既定のデータストアに自動的にアップロードされます。 この例では、`diabetes.csv` ファイルは **workspaceblobstore** データストアの **LocalUpload** フォルダーにアップロードされます。 \n",
        "\n",
        "ローカル ファイルからデータ資産を作成するには、次のセルを実行します。"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "source": [
        "`URI_FOLDER` データ資産を作成するには、特定のフォルダーを指すパスを指定する必要があります。 パスは、ローカル パスまたはクラウド パスにすることができます。\n",
        "\n",
        "次の例では、\"クラウド\" パスを参照してデータ資産を作成します。** パスはまだ存在していなくてかまいません。 フォルダーは、データがパスにアップロードされるときに作成されます。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1666790818340
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [],
      "source": [
        "`MLTable` データ資産を作成するには、MLTable ファイルを含むフォルダーを指すパスを指定する必要があります。 パスは、ローカル パスまたはクラウド パスにすることができます。 \n",
        "\n",
        "次の例では、MLTable の CSV ファイルを含む \"ローカル\" パスを参照して、データ資産を作成します。** "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "source": [
        "新しいデータ資産が作成されたことを確認するには、ワークスペース内のすべてのデータ資産をもう一度一覧表示します。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1666790835295
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [],
      "source": [
        "## ノートブック内のデータを読み取る\n",
        "\n",
        "最初は、ノートブック内のデータ資産を操作して、データを探索し、機械学習モデルを試すことができます。 種類が `URI_FILE` または `URI_FOLDER` のデータ資産は、通常のデータ読み取りの場合と同様に読み取ることができます。 たとえば、データ資産が指す CSV ファイルを読み込む場合は、pandas 関数 `read_csv()` を使用できます。 \n",
        "\n",
        "種類が `MLTable` のデータ資産は、スキーマとデータの解釈方法を指定した **MLTable** ファイルによって既に \"読み取り済み\" です。** データは既に \"読み取り済み\" であるため、MLTable データ資産を pandas のデータフレームに簡単に変換できます。** \n",
        "\n",
        "`mltable` ライブラリをインストールする必要があります (ターミナルで行いました)。 その後、データ資産をデータフレームに変換し、データを視覚化できます。  "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "source": [
        "## ジョブでデータを使用する\n",
        "\n",
        "実験にノートブックを使用した後。 スクリプトを使用して機械学習モデルをトレーニングできます。 スクリプトはジョブとして実行でき、ジョブごとに入力と出力を指定できます。 \n",
        "\n",
        "ジョブの入力または出力として、**データ資産**または**データストア パス**のどちらでも使用できます。 \n",
        "\n",
        "次に示すセルの場合、**src** フォルダーに **move-data.py** スクリプトを作成します。 スクリプトは、`read_csv()` 関数を使用して入力データを読み取ります。 その後、スクリプトはデータを CSV ファイルとして出力パスに格納します。"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "source": [
        "**move-data.py** スクリプトを実行するジョブを送信するには、次のセルを実行します。 \n",
        "\n",
        "このジョブは、入力としてローカル **diabetes.csv** ファイルを指すデータ資産 `diabetes-local` を使用するように構成されています。 出力は、新しいデータストア `blob_training_data` 内のフォルダーを指すパスです。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1666790852019
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [],
      "source": [
        "from azure.ai.ml.entities import Data\n",
        "from azure.ai.ml.constants import AssetTypes\n",
        "\n",
        "my_path = './data/diabetes.csv'\n",
        "\n",
        "my_data = Data(\n",
        "    path=my_path,\n",
        "    type=AssetTypes.URI_FILE,\n",
        "    description=\"Data asset pointing to a local file, automatically uploaded to the default datastore\",\n",
        "    name=\"diabetes-local\"\n",
        ")\n",
        "\n",
        "ml_client.data.create_or_update(my_data)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "source": [
        "To create a `URI_FOLDER` data asset, you have to specify a path that points to a specific folder. The path can be a local path or cloud path.\n",
        "\n",
        "In the example below, you'll create a data asset by referencing a *cloud* path. The path doesn't have to exist yet. The folder will be created when data is uploaded to the path."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1666793449117
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [],
      "source": [
        "from azure.ai.ml.entities import Data\n",
        "from azure.ai.ml.constants import AssetTypes\n",
        "\n",
        "datastore_path = 'azureml://datastores/blob_training_data/paths/data-asset-path/'\n",
        "\n",
        "my_data = Data(\n",
        "    path=datastore_path,\n",
        "    type=AssetTypes.URI_FOLDER,\n",
        "    description=\"Data asset pointing to data-asset-path folder in datastore\",\n",
        "    name=\"diabetes-datastore-path\"\n",
        ")\n",
        "\n",
        "ml_client.data.create_or_update(my_data)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "source": [
        "To create a `MLTable` data asset, you have to specify a path that points to a folder which contains a MLTable file. The path can be a local path or cloud path. \n",
        "\n",
        "In the example below, you'll create a data asset by referencing a *local* path which contains an MLTable and CSV file. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1666790884342
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [],
      "source": [
        "from azure.ai.ml.entities import Data\n",
        "from azure.ai.ml.constants import AssetTypes\n",
        "\n",
        "local_path = 'data/'\n",
        "\n",
        "my_data = Data(\n",
        "    path=local_path,\n",
        "    type=AssetTypes.MLTABLE,\n",
        "    description=\"MLTable pointing to diabetes.csv in data folder\",\n",
        "    name=\"diabetes-table\"\n",
        ")\n",
        "\n",
        "ml_client.data.create_or_update(my_data)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "source": [
        "To verify that the new data assets have been created, you can list all data assets in the workspace again:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1666790894246
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [],
      "source": [
        "datasets = ml_client.data.list()\n",
        "for ds_name in datasets:\n",
        "    print(ds_name.name)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "source": [
        "## Read data in notebook\n",
        "\n",
        "Initially, you may want to work with data assets in notebooks, to explore the data and experiment with machine learning models. Any `URI_FILE` or `URI_FOLDER` type data assets are read as you would normally read data. For example, to read a CSV file a data asset points to, you can use the pandas function `read_csv()`. \n",
        "\n",
        "A `MLTable` type data asset is already *read* by the **MLTable** file, which specifies the schema and how to interpret the data. Since the data is already *read*, you can easily convert a MLTable data asset to a pandas dataframe. \n",
        "\n",
        "You'll need to install the `mltable` library (which you did in the terminal). Then, you can convert the data asset to a dataframe and visualize the data.  "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1666792246101
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [],
      "source": [
        "import mltable\n",
        "\n",
        "registered_data_asset = ml_client.data.get(name='diabetes-table', version=1)\n",
        "tbl = mltable.load(f\"azureml:/{registered_data_asset.id}\")\n",
        "df = tbl.to_pandas_dataframe()\n",
        "df.head(5)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "source": [
        "## Use data in a job\n",
        "\n",
        "After using a notebook for experimentation. You can use scripts to train machine learning models. A script can be run as a job, and for each job you can specify inputs and outputs. \n",
        "\n",
        "You can use either **data assets** or **datastore paths** as inputs or outputs of a job. \n",
        "\n",
        "The cells below creates the **move-data.py** script in the **src** folder. The script reads the input data with the `read_csv()` function. The script then stores the data as a CSV file in the output path."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [],
      "source": [
        "import os\n",
        "\n",
        "# create a folder for the script files\n",
        "script_folder = 'src'\n",
        "os.makedirs(script_folder, exist_ok=True)\n",
        "print(script_folder, 'folder created')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [],
      "source": [
        "%%writefile $script_folder/move-data.py\n",
        "# import libraries\n",
        "import argparse\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from pathlib import Path\n",
        "\n",
        "def main(args):\n",
        "    # read data\n",
        "    df = get_data(args.input_data)\n",
        "\n",
        "    output_df = df.to_csv((Path(args.output_datastore) / \"diabetes.csv\"), index = False)\n",
        "\n",
        "# function that reads the data\n",
        "def get_data(path):\n",
        "    df = pd.read_csv(path)\n",
        "\n",
        "    # Count the rows and print the result\n",
        "    row_count = (len(df))\n",
        "    print('Analyzing {} rows of data'.format(row_count))\n",
        "    \n",
        "    return df\n",
        "\n",
        "def parse_args():\n",
        "    # setup arg parser\n",
        "    parser = argparse.ArgumentParser()\n",
        "\n",
        "    # add arguments\n",
        "    parser.add_argument(\"--input_data\", dest='input_data',\n",
        "                        type=str)\n",
        "    parser.add_argument(\"--output_datastore\", dest='output_datastore',\n",
        "                        type=str)\n",
        "\n",
        "    # parse args\n",
        "    args = parser.parse_args()\n",
        "\n",
        "    # return args\n",
        "    return args\n",
        "\n",
        "# run script\n",
        "if __name__ == \"__main__\":\n",
        "    # add space in logs\n",
        "    print(\"\\n\\n\")\n",
        "    print(\"*\" * 60)\n",
        "\n",
        "    # parse args\n",
        "    args = parse_args()\n",
        "\n",
        "    # run main function\n",
        "    main(args)\n",
        "\n",
        "    # add space in logs\n",
        "    print(\"*\" * 60)\n",
        "    print(\"\\n\\n\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "To submit a job that runs the **move-data.py** script, run the cell below. \n",
        "\n",
        "The job is configured to use the data asset `diabetes-local`, pointing to the local **diabetes.csv** file as input. The output is a path pointing to a folder in the new datastore `blob_training_data`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1666794414231
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [],
      "source": [
        "from azure.ai.ml import Input, Output\n",
        "from azure.ai.ml.constants import AssetTypes\n",
        "from azure.ai.ml import command\n",
        "\n",
        "# configure input and output\n",
        "my_job_inputs = {\n",
        "    \"local_data\": Input(type=AssetTypes.URI_FILE, path=\"azureml:diabetes-local:1\")\n",
        "}\n",
        "\n",
        "my_job_outputs = {\n",
        "    \"datastore_data\": Output(type=AssetTypes.URI_FOLDER, path=\"azureml://datastores/blob_training_data/paths/datastore-path\")\n",
        "}\n",
        "\n",
        "# configure job\n",
        "job = command(\n",
        "    code=\"./src\",\n",
        "    command=\"python move-data.py --input_data ${{inputs.local_data}} --output_datastore ${{outputs.datastore_data}}\",\n",
        "    inputs=my_job_inputs,\n",
        "    outputs=my_job_outputs,\n",
        "    environment=\"AzureML-sklearn-0.24-ubuntu18.04-py37-cpu@latest\",\n",
        "    compute=\"aml-cluster\",\n",
        "    display_name=\"move-diabetes-data\",\n",
        "    experiment_name=\"move-diabetes-data\"\n",
        ")\n",
        "\n",
        "# submit job\n",
        "returned_job = ml_client.create_or_update(job)\n",
        "aml_url = returned_job.studio_url\n",
        "print(\"Monitor your job at\", aml_url)"
      ]
    }
  ],
  "metadata": {
    "kernel_info": {
      "name": "python38-azureml"
    },
    "kernelspec": {
      "display_name": "Python 3.8 - AzureML",
      "language": "python",
      "name": "python38-azureml"
    },
    "microsoft": {
      "host": {
        "AzureML": {
          "notebookHasBeenCompleted": true
        }
      }
    },
    "nteract": {
      "version": "nteract-front-end@1.0.0"
    },
    "vscode": {
      "interpreter": {
        "hash": "f2b2cd046deda8eabef1e765a11d0ec9aa9bd1d31d56ce79c815a38c323e14ec"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}