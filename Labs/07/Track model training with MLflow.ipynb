{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# MLflow を使用してノートブックでモデル トレーニングを追跡する\n",
        "\n",
        "ノートブックで MLflow を使用して、トレーニングするすべてのモデルを追跡できます。 Azure Machine Learning コンピューティング インスタンスでこのノートブックを実行するので、MLflow を設定する必要はありません。既にインストールされ、統合されています。 \n",
        "\n",
        "いくつかのデータを準備し、糖尿病を予測するモデルをトレーニングします。 自動ログ記録とカスタム ログを使用して、ノートブックで MLflow を使用する方法を確認します。\n",
        "\n",
        "## 開始する前に\n",
        "\n",
        "このノートブックでコードを実行するには、**azureml-ai-ml** パッケージの最新バージョンが必要です。 次のセルを実行して、パッケージがインストールされていることを確認します。\n",
        "\n",
        "> **注**:\n",
        "> **azure-ai-ml** パッケージがインストールされていない場合は、`pip install azure-ai-ml` を実行してインストールします。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [],
      "source": [
        "## ワークスペースに接続する\n",
        "\n",
        "必要な SDK パッケージがインストールされているため、ワークスペースに接続できます。\n",
        "\n",
        "ワークスペースに接続するには、識別子パラメーター (サブスクリプション ID、リソース グループ名、ワークスペース名) が必要です。 リソース グループ名とワークスペース名は既に入力されています。 コマンドを完了するには、サブスクリプション ID のみが必要です。\n",
        "\n",
        "必要なパラメーターを見つけるには、Studio の右上にあるサブスクリプションとワークスペース名をクリックします。 右側にペインが開きます。\n",
        "\n",
        "<p style=\"color:red;font-size:120%;background-color:yellow;font-weight:bold\"> サブスクリプション ID をコピーし、**YOUR-SUBSCRIPTION-ID** をコピーした値に置き換えます。 </p>"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## MLflow を構成する\n",
        "\n",
        "Azure Machine Learning スタジオのコンピューティング インスタンスでこのノートブックを実行しているので、MLflow を構成する必要はありません。 \n",
        "\n",
        "それでも、必要なライブラリが実際にインストールされていることを確認することをお勧めします。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1668168317138
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [],
      "source": [
        "## データを準備する\n",
        "\n",
        "糖尿病分類モデルをトレーニングします。 トレーニング データは、**diabetes.csv** として **data** フォルダーに格納されます。 \n",
        "\n",
        "まず、データを読み取りましょう。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1668168324029
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [],
      "source": [
        "次に、データを特徴とラベル (糖尿病) に分割します。"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "これで、次の 4 つのデータフレームが作成されました。\n",
        "\n",
        "- `X_train`: 特徴を含むトレーニング データセット。\n",
        "- `X_test`: 特徴を含むテスト データセット。\n",
        "- `y_train`: トレーニング データセットのラベル。\n",
        "- `y_test`: テスト データセットのラベル。\n",
        "\n",
        "これらを使用して、トレーニングするモデルのトレーニングと評価を行います。\n",
        "\n",
        "## MLflow 実験を作成する\n",
        "\n",
        "機械学習モデルをトレーニングする準備ができたので、まず MLflow 実験を作成します。 実験を作成すると、1 つの実験内のすべての実行をグループ化し、スタジオで実行をより簡単に見つけることができます。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1668168155287
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [],
      "source": [
        "## モデルをトレーニングおよび追跡する\n",
        "\n",
        "トレーニングするモデルを追跡するには、MLflow を使用して自動ログを有効にします。 次のセルは、ロジスティック回帰を使用して分類モデルをトレーニングします。 評価メトリックは MLflow によって自動的に作成され、ログに記録されるため、計算する必要はありません。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1668168179344
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [],
      "source": [
        "MLflow でカスタム ログを使用することもできます。 自動ログにカスタム ログを追加することも、カスタム ログのみを使用することもできます。\n",
        "\n",
        "scikit-learn を使用して、さらに 2 つのモデルをトレーニングしてみましょう。 前に `mlflow.sklearn.autolog()` コマンドを実行したので、MLflow は scikit-learn でトレーニングされたすべてのモデルを自動的にログするようになりました。 自動ログを無効にするには、次のセルを実行します。"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "これで、カスタム ログのみを使用してモデルをトレーニングおよび追跡できるようになりました。 \n",
        "\n",
        "次のセルを実行すると、1 つのパラメーターと 1 つのメトリックのみがログされます。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1668175953133
        },
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [],
      "source": [
        "モデルを追跡する理由は、トレーニングするモデルの結果をさまざまなハイパーパラメーター値と比較するためです。 \n",
        "\n",
        "たとえば、正則化率が 0.1 のロジスティック回帰モデルをトレーニングしたとします。 次に、別のモデルをトレーニングしますが、今回は正則化率が 0.01 です。 正確性も追跡しているため、パフォーマンスの高いモデルの結果を比較して決定できます。"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "モデルの結果を追跡するもう 1 つの理由は、別の推定器をテストする場合です。 これまでにトレーニングしたすべてのモデルでは、ロジスティック回帰推定器を使用しました。 \n",
        "\n",
        "次のセルを実行して、デシジョン ツリー分類子推定器を使用してモデルをトレーニングし、他の実行と比較して正確性が高いかどうかを確認します。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1668175956555
        },
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [],
      "source": [
        "最後に、成果物をログに記録してみましょう。 成果物には、任意のファイルを指定できます。 たとえば、ROC 曲線をプロットし、プロットをイメージとして保存できます。 イメージは成果物としてログに記録できます。 \n",
        "\n",
        "次のセルを実行して、パラメーター、メトリック、成果物をログします。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1668175959902
        },
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [],
      "source": [
        "Azure Machine Learning スタジオの [ジョブ] ページでモデルの結果を確認します。 \n",
        "\n",
        "- パラメーターは、 **[概要]** タブの **[パラメーター]** の下にあります。\n",
        "- メトリックは、 **[概要]** タブの **[メトリック]** と **[メトリック]** タブにあります。\n",
        "- 成果物は、 **[出力 + ログ]** タブにあります。\n",
        "\n",
        "![[ジョブ] ページの [出力 + ログ] タブのスクリーンショット。](./images/output-logs.png)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "You now have four dataframes:\n",
        "\n",
        "- `X_train`: The training dataset containing the features.\n",
        "- `X_test`: The test dataset containing the features.\n",
        "- `y_train`: The label for the training dataset.\n",
        "- `y_test`: The label for the test dataset.\n",
        "\n",
        "You'll use these to train and evaluate the models you'll train.\n",
        "\n",
        "## Create an MLflow experiment\n",
        "\n",
        "Now that you're ready to train machine learning models, you'll first create an MLflow experiment. By creating the experiment, you can group all runs within one experiment and make it easier to find the runs in the studio."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [],
      "source": [
        "import mlflow\n",
        "experiment_name = \"mlflow-experiment-diabetes\"\n",
        "mlflow.set_experiment(experiment_name)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Train and track models\n",
        "\n",
        "To track a model you train, you can use MLflow and enable autologging. The following cell will train a classification model using logistic regression. You'll notice that you don't need to calculate any evaluation metrics because they're automatically created and logged by MLflow."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1668176121803
        },
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [],
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        "\n",
        "with mlflow.start_run():\n",
        "    mlflow.sklearn.autolog()\n",
        "\n",
        "    model = LogisticRegression(C=1/0.1, solver=\"liblinear\").fit(X_train, y_train)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "You can also use custom logging with MLflow. You can add custom logging to autologging, or you can use only custom logging.\n",
        "\n",
        "Let's train two more models with scikit-learn. Since you ran the `mlflow.sklearn.autolog()` command before, MLflow will now automatically log any model trained with scikit-learn. To disable the autologging, run the following cell:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1668177101622
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [],
      "source": [
        "mlflow.sklearn.autolog(disable=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Now, you can train and track models using only custom logging. \n",
        "\n",
        "When you run the following cell, you'll only log one parameter and one metric."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [],
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        "import numpy as np\n",
        "\n",
        "with mlflow.start_run():\n",
        "    model = LogisticRegression(C=1/0.1, solver=\"liblinear\").fit(X_train, y_train)\n",
        "\n",
        "    y_hat = model.predict(X_test)\n",
        "    acc = np.average(y_hat == y_test)\n",
        "\n",
        "    mlflow.log_param(\"regularization_rate\", 0.1)\n",
        "    mlflow.log_metric(\"Accuracy\", acc)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "The reason why you'd want to track models, could be to compare the results of models you train with different hyperparameter values. \n",
        "\n",
        "For example, you just trained a logistic regression model with a regularization rate of 0.1. Now, train another model, but this time with a regularization rate of 0.01. Since you're also tracking the accuracy, you can compare and decide which rate results in a better performing model."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1668177593117
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [],
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        "import numpy as np\n",
        "\n",
        "with mlflow.start_run():\n",
        "    model = LogisticRegression(C=1/0.01, solver=\"liblinear\").fit(X_train, y_train)\n",
        "\n",
        "    y_hat = model.predict(X_test)\n",
        "    acc = np.average(y_hat == y_test)\n",
        "\n",
        "    mlflow.log_param(\"regularization_rate\", 0.01)\n",
        "    mlflow.log_metric(\"Accuracy\", acc)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Another reason to track your model's results is when you're testing another estimator. All models you've trained so far used the logistic regression estimator. \n",
        "\n",
        "Run the following cell to train a model with the decision tree classifier estimator and review whether the accuracy is higher compared to the other runs."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1668177807904
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [],
      "source": [
        "from sklearn.tree import DecisionTreeClassifier\n",
        "import numpy as np\n",
        "\n",
        "with mlflow.start_run():\n",
        "    model = DecisionTreeClassifier().fit(X_train, y_train)\n",
        "\n",
        "    y_hat = model.predict(X_test)\n",
        "    acc = np.average(y_hat == y_test)\n",
        "\n",
        "    mlflow.log_param(\"estimator\", \"DecisionTreeClassifier\")\n",
        "    mlflow.log_metric(\"Accuracy\", acc)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Finally, let's try to log an artifact. An artifact can be any file. For example, you can plot the ROC curve and store the plot as an image. The image can be logged as an artifact. \n",
        "\n",
        "Run the following cell to log a parameter, metric, and an artifact."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [],
      "source": [
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.metrics import roc_curve\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "with mlflow.start_run():\n",
        "    model = DecisionTreeClassifier().fit(X_train, y_train)\n",
        "\n",
        "    y_hat = model.predict(X_test)\n",
        "    acc = np.average(y_hat == y_test)\n",
        "\n",
        "    # plot ROC curve\n",
        "    y_scores = model.predict_proba(X_test)\n",
        "\n",
        "    fpr, tpr, thresholds = roc_curve(y_test, y_scores[:,1])\n",
        "    fig = plt.figure(figsize=(6, 4))\n",
        "    # Plot the diagonal 50% line\n",
        "    plt.plot([0, 1], [0, 1], 'k--')\n",
        "    # Plot the FPR and TPR achieved by our model\n",
        "    plt.plot(fpr, tpr)\n",
        "    plt.xlabel('False Positive Rate')\n",
        "    plt.ylabel('True Positive Rate')\n",
        "    plt.title('ROC Curve')\n",
        "    plt.savefig(\"ROC-Curve.png\")\n",
        "\n",
        "    mlflow.log_param(\"estimator\", \"DecisionTreeClassifier\")\n",
        "    mlflow.log_metric(\"Accuracy\", acc)\n",
        "    mlflow.log_artifact(\"ROC-Curve.png\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Review the model's results on the Jobs page of the Azure Machine Learning studio. \n",
        "\n",
        "- You'll find the parameters under **Params** in the **Overview** tab.\n",
        "- You'll find the metrics under **Metrics** in the **Overview** tab, and in the **Metrics** tab.\n",
        "- You'll find the artifacts in the **Outputs + logs** tab.\n",
        "\n",
        "![Screenshot of outputs and logs tab on the Jobs page.](./images/output-logs.png)"
      ]
    }
  ],
  "metadata": {
    "interpreter": {
      "hash": "f2b2cd046deda8eabef1e765a11d0ec9aa9bd1d31d56ce79c815a38c323e14ec"
    },
    "kernel_info": {
      "name": "python38-azureml"
    },
    "kernelspec": {
      "display_name": "Python 3.8 - AzureML",
      "language": "python",
      "name": "python38-azureml"
    },
    "microsoft": {
      "host": {
        "AzureML": {
          "notebookHasBeenCompleted": true
        }
      }
    },
    "nteract": {
      "version": "nteract-front-end@1.0.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}